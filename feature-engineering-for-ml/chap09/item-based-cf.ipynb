{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9장 다시 피처로: 학술 논문 추천 시스템 구축\n",
    "- item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9장에서 사용할 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/mag_papers/'\n",
    "model_df = pd.read_json(file_path + \"mag_papers_0.txt\", lines=True)\n",
    "model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제에서 2만 건의 데이터만 사용\n",
    "\n",
    "df20000 = model_df[:20000, :]\n",
    "df20000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df20000.to_json(file_path + \"mag_subset20k.txt\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __첫번째 단계: 데이터 가져오기, 정제하기, 피처 파싱하기__\n",
    "- 모든 과학 실험과 맟나가지로 이 작업도 가설로 시작할 것이다. __이 경우에는 거의 같은 시기에 비슷한 연구 분야에서 출간된 논문이 사용자에게 가장 유용할 것이라고 가정한다.__ 그래서 전체 데이터셋의 하위 샘플에서 이와 관련된 필드를 파싱하는 단순한 접근법을 사용할 것이다. 간단한 희소 배열을 생성한 다음에 항목 기반 협업 필터를 전체 항목 배열에 적용해 좋은 결과가 나오는지 확인해보자.\n",
    "\n",
    "항목 기반 협업 필터는 항목을 비교하는 유사도 점수에 좌우된다. 이 경우에는 코사인 유사도가 두 개의 0이 아닌 벡터를 비교하기 위해 사용된다. 실제로 다음 예제는 양수의 공간에서 코사인 유사도를 보완하는 코사인 거리를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9-1. Import + filter data\n",
    "- 단순 접근법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.read_json('data/mag_papers/mag_subset20K.txt', lines=True)\n",
    "model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어가 아닌 논문 제외\n",
    "# 제목이 중복인 것 제외\n",
    "\n",
    "model_df = model_df[model_df.lang == 'en'].drop_duplicates(subset='title', keep='first')\n",
    "\n",
    "# abstract, authors, fos, keytwords, year, title 컬럼만 사용\n",
    "model_df = model_df.drop(['doc_type', \n",
    "                          'doi', 'id', \n",
    "                          'issue', 'lang', \n",
    "                          'n_citation', \n",
    "                          'page_end', \n",
    "                          'page_start', \n",
    "                          'publisher', \n",
    "                          'references',\n",
    "                          'url', \n",
    "                          'venue', \n",
    "                          'volume'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9-2. Collaborative filtering stage 1: Build item feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import getsizeof\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연구분야\n",
    "unique_fos = sorted({feature \n",
    "                     for paper_row in model_df.fos.fillna('0')\n",
    "                     for featrue in paper_row})\n",
    "\n",
    "# 출간년도\n",
    "unique_year = sorted(model_df['year'].astype('str').unique())\n",
    "\n",
    "print(\"unique_fos  :\", len(unique_fos))\n",
    "print(\"unique_year :\", len(unique_year))\n",
    "print(\"total       :\", len(unique_fos + unique_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연구분야가 null이 아닌 데이터 수\n",
    "model_df.shape[0] - pd.isnull(model_df['fos']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[unique_fos[i] for i in sorted(random.sample(range(len(unique_fos)), 15)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_array(x, unique_array):\n",
    "    row_dict = {}\n",
    "    for i in x.index:\n",
    "        var_dict = {}\n",
    "        \n",
    "        for j in range(len(unique_array)):\n",
    "            if type(x[i]) is list:\n",
    "                if unique_array[j] in x[i]:\n",
    "                    var_dict.update({unique_array[j]: 1})\n",
    "                else:\n",
    "                    var_dict.update({unique_array[j]: 0})\n",
    "            else:\n",
    "                if unique_array[j] == str(x[i]):\n",
    "                    var_dict.update({unique_array[j]: 1})\n",
    "                else:\n",
    "                    var_dict.update({unique_array[j]: 0})\n",
    "        \n",
    "        row_dict.update({i : var_dict})\n",
    "    \n",
    "    feature_df = pd.DataFrame.from_dict(row_dict, dtype='str').T\n",
    "    \n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time year_features = feature_array(model_df['year'], unique_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time fos_features = feature_array(model_df['fos'], unique_fos)\n",
    "\n",
    "print(\"Size of fos feature array: \", getsizeof(fos_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(year_features.shape)\n",
    "print(fos_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_features.shape[1] + fos_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10399 X 7760 array\n",
    "%time first_features = fos_features.join(year_features).T\n",
    "\n",
    "first_size = getsizeof(first_features)\n",
    "print(\"Size of first feature array: \", first_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9-3. Collaborative filtering stage 2: Search for similar items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_collab_filter(features_df):\n",
    "    item_similarities = pd.DataFrame(index=features_df.columns, columns=features_df.columns)\n",
    "    \n",
    "    for i in features_df.columns:\n",
    "        for j in featrues_df.columns:\n",
    "            item_similarities.loc[i][j] = 1 - cosine(features_df[i].astype('float'), features_df[j].astype('float'))\n",
    "    \n",
    "    return item_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time first_items = item_collab_filter(first_features.loc[:, 0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9-4. Heatmap of paper recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그림 9-3\n",
    "sns.set()\n",
    "ax = sns.heatmap(first_items.fillna(0),\n",
    "                vmin=0, vmat=1,\n",
    "                cmap='Y1GnBu',\n",
    "                xticklabels=250, yticklabels=250)\n",
    "ax.tick_params(labelsiz=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9-5. Item-based collaborative filtering recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_recommender(paper_index, items_df):\n",
    "    print(\"Based on the paper: \\nindex = \", paper_index)\n",
    "    print(model_df.iloc[paper_index])\n",
    "    top_results = item_df.loc[paper_index].sort_values(ascending=False).head(4)\n",
    "    print(\"\\nTop3 results: \")\n",
    "    order = 1\n",
    "    \n",
    "    for i in top_results.index.tolist()[-3:]:\n",
    "        print(order, '. Paper index = ', i)\n",
    "        print(\"Similarity score: \", top_results[i])\n",
    "        print(model_df.iloc[i], \"\\n\")\n",
    "        if order < 5: order += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_recommender(2, first_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __두번째 단계: 피처 엔지니어링과 더 똑똑한 모델__\n",
    "- 커다란 희소 배열을 생성하고 그것을 강제적으로 필터에 밀어너는 첫 번째 접근법은 다양한 방식으로 개선될 수 있다. 다음 단계에서는 처음에 사용한 두 개의 피처에 더 나은 기법을 적용하고 더 빠르게 반복 처리를 하도록 항목 기반 협업 필터를 수정하는 데 중점을 둘 것이다. 우선 우리의 가설에 사용한 두 개의 변수에 몇 가지 피처 엔지니어링 기법을 적용해보자. 앞서 개발한 피처를 더 자세히 살펴보면, 각 변수의 유형에 맞춰 추천 시스템을 위한 '더 나은'피처롤 변환시킬 방법을 선택할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9-6. Fixed-width binning + dummy coding(part 1)\n",
    "- 고정 폭 비닝 + 더미 코딩(파트1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['year'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Year spread: \", model_df['year'].min(), \" - \", model_df['year'].max())\n",
    "print(\"Quantile spread:\\n\", model_df['year'].quantile([0.25, 0.5, 0.75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그림 9-5. year의 분포 확인\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "model_df['year'].hist(ax=ax, bins=model_df['year'].max() - model_df['year'].min())\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.set_xlabel(\"Year Count\", fontsize=12)\n",
    "ax.set_ylabel(\"Occurrence\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9-7. Fixed-width binning + dummy coding (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin은 데이터의 수가 아니라 변수의 범위를 기준으로 설정한다.\n",
    "model_df['year'].max() - model_df['year'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year 피처를 10년 단위로 비닝\n",
    "bins = int(round((model_df['year'].max() = model_df['year'].min()) / 10))\n",
    "\n",
    "temp_df = pd.DataFrame(index = model_df.index)\n",
    "temp_df['yearBinned'] = pd.cut(model_df['year'].tolist(), bins, precision = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year 피처를 10년 단위로 비닝함으로써 피처 공간을 156에서 19로 줄인다\n",
    "print(\"We have reduced from\", len(mode_df['year'].unique()), \n",
    "     \"to\", len(temp_df['yearBinned'].values.unique()), \"features representing the year.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_yrs = pd.get_dummies(temp_df['yearBinned'])\n",
    "X_yrs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_yrs.columns.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그림 9-6. 비닝한 year의 분포 확인\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "X_yrs.sum().plot.bar(ax = ax)\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.set_xlabel(\"Binned Years\", fontsize=12)\n",
    "ax.set_ylabel(\"Counts\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9-8. Converting bag-of-phrases pd.Series to NumPy sparse array\n",
    "- Pandas 시리즈인 bag-of-pharses를 NumPy 희소 배열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fos = fos_features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 객체의 크기를 보면 나중에 어떤 차이를 만들게 될지 예상할 수 있다.\n",
    "print('Our pandas Series, in bytes: ', getsizeof(fos_features))\n",
    "print('Our hashed numpy array, in bytes: ', getsizeof(X_fos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9-9. Collaborative filtering stages 1 + 2: Build item feature matrix, search for similar items\n",
    "- 항목 피처 행렬 생성, 유사 항목 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklear.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DicVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_yrs.shape[1] + X_fos.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10399 x 7623 array\n",
    "\n",
    "%time second_features = np.append(X_fos, X_yrs, axis=1)\n",
    "\n",
    "second_size = getsizeof(second_features)\n",
    "print(\"Size of second feature array, in bytes: \", scond_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The power of feature engineering saves us, in bytes: \", getsizeof(fos_features) - second_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piped_collab_filter(features_matrix, index, top_n):\n",
    "    item_similarities = 1 - cosine_similarity(features_matrix[index:index+1], features_matrix).flatten()\n",
    "    related_indices = [i for i in item_similarities.argsort()[::-1] if i != index]\n",
    "    \n",
    "    return [ (index, item_similarities[index]) for index in related_indices][0:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9-10. Item-based collaborative filtering recoomendations: Take 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_recommender(items_df, paper_index, top_n):\n",
    "    if paper_index in model_df.index:\n",
    "        \n",
    "        print('Based on the paper:')\n",
    "        print('Paper index = ', model_df.loc[paper_index].name)\n",
    "        print('Title :', model_df.loc[paper_index]['title'])\n",
    "        print('FOS :', model_df.loc[paper_index]['fos'])\n",
    "        print('Year :', model_df.loc[paper_index]['year'])\n",
    "        print('Abstract :', model_df.loc[paper_index]['abstract'])\n",
    "        print('Authors :', model_df.loc[paper_index]['authors'], '\\n')\n",
    "        \n",
    "        # 요청된 DataFrame 인덱스에 대한 위치 인덱스 정의\n",
    "        array_ix = model_df.index.get_loc(paper_index)\n",
    "        \n",
    "        top_results = piped_collab_filter(items_df, array_ix, top_n)\n",
    "        \n",
    "        print(\"\\nTop\", top_n, \"results: \")\n",
    "        \n",
    "        order = 1\n",
    "        \n",
    "        for i in range(len(top_results)):\n",
    "            print(order,'. Paper index = ', model_df.iloc[top_results[i][0]].name)\n",
    "            print('Similarity score: ', top_results[i][1])\n",
    "            print('Title :', model_df.iloc[top_results[i][0]]['title'])\n",
    "            print('FOS :', model_df.iloc[top_results[i][0]]['fos'])\n",
    "            print('Year :', model_df.iloc[top_results[i][0]]['year'])\n",
    "            print('Abstract :', model_df.iloc[top_results[i][0]]['abstract'])\n",
    "            print('Authors :', model_df.iloc[top_results[i][0]]['authors'], '\\n')\n",
    "            if order < top_n: order += 1\n",
    "        \n",
    "    else:\n",
    "        print('Whoops! Choose another paper. Try something from here: \\n', model_df.index[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_recommender(second_feature, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 9-11. Maintaining index assignment during conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.loc[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.iloc[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.index.get_loc(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __세 번째 단계: 추가 피쳐 = 추가 정보__\n",
    "- 이 실험은 출간 년도와 연구 분야가 유사한 논문을 추천하기에 충분할 것이라는 처음의 가설을 지지하지 못하고 있다. 이 시점에서 몇가지 옵션이 있다.\n",
    "    - 원본 데이터셋을 좀 더 많이 사용해 더 나은 결과를 얻을 수 있는지 확인해본다.\n",
    "    - 좋은 추천 결과를 제공할 수 있을 만큼 충분한 데이터인지 좀 더 시간을 들여 탐색한다.\n",
    "    - 현재 모델에 피처를 더 추가한다.\n",
    "\n",
    "첫 번째 옵션은 샘플링한 데이터에 문제가 있다고 가정한다. 그것이 사실일 수도 있지만, 이는 더 나은 결과를 얻기 위해 데이터 더미를 휘젓는 것과 비슷하다.\n",
    "\n",
    "두 번째 옵션은 기본적으로 원본 데이터에 대해 더 많이 이해할 수 있게 해준다. 이 옵션은 탐색 과정에서 피처와 모델 선택에 따른 변경 사항에 대해 지속적으로 재검토돼야 한다. 이 예제에서 선택한 초기 샘플은 이를 반영하고 있다. 데이터셋에서 사용할 수 있는 변수들이 많이 있으믈 이 옵션을 더 이상 진행하지 않는다.\n",
    "\n",
    "세 번째 옵션을 적용해 피처를 더 추가함으로써 현재 모델을 더 발전시켜보자. 각 항목에 대해 더 많은 정보를 제공하면 유사도 점수를 향상시키고 더 나은 추천 결과를 얻을 수 있다. 초기 탐색을 기초로 다음 단계에서는 가장 많은 정보를 가진 초록(abstract)과 저자(authors)필드에 중점을 둔다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학술 논문 추천 시스템: 테이크 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9-12. Stopwords + tf-idf\n",
    "- 불용어 처리 + tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn을 사용하기 위해 NaN 항목을 채워준다\n",
    "filled_df = model_df.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_df['abstract'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract: 불용어, 빈도기반 필터링\n",
    "vectorizer = TfidVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "X_abstract = vectorizer.fit_transform(filled_df['abstract'])\n",
    "\n",
    "X_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"n_samples: %d, n_features: %d\" % X_abstract.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_yrs.shape[1] + X_fos.shape[1] + X_abstract.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10399 x 56139 array\n",
    "\n",
    "%time third_features = np.append(second_features, X_abstract.toarray(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_recommender(third_feature, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9-13. One-hot encoding using scikit-learn's DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df = pd.DataFrame(filled_df.authors)\n",
    "authors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_list = []\n",
    "\n",
    "for row in authors_df.itertuples():\n",
    "    # 각 시리즈 인덱스부터 딕셔너리 생성\n",
    "    if type(row.authors) is str:\n",
    "        y = {'None': row.Index}\n",
    "    if type(row.authors) is list:\n",
    "        # 이 키와 값을 딕셔너리에 추가\n",
    "        y = dict.fromkeys(row.authors[0].values(), row.Index)\n",
    "    authors_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = DicVectorizer(sparse=False)\n",
    "D = authors_list\n",
    "X_authors = v.fit_transform(D)\n",
    "\n",
    "X_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"n_samples: %d, n_features: %d\" % X_authors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_yrs.shape[1] + X_fos.shape[1] + X_abstract.shape[1] + X_authors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10399 x 70167 array\n",
    "\n",
    "%time fourth_features = np.append(third_features, X_authors, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9-14. Item-based collaborative filtering recommendation: Take 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_recommender(fourth_features, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __NEXT STEPS__\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jipiration",
   "language": "python",
   "name": "jipiration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
